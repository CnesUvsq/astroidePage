<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.14.1 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Quick-Start Guide - ASTROIDE</title>
<meta name="description" content="ASTROIDE is a distributed data server for astronomical data.">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="ASTROIDE">
<meta property="og:title" content="Quick-Start Guide">
<meta property="og:url" content="http://localhost:4000/guide/">












  

  


<link rel="canonical" href="http://localhost:4000/guide/">







  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "ASTROIDE",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="ASTROIDE Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--posts">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="http://localhost:4000/"><img src="astroide.png"></a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/guide/" >Quick-Start Guide</a>
            </li><li class="masthead__menu-item">
              <a href="/about/" >About</a>
            </li><li class="masthead__menu-item">
              <a href="/contact/" >Contact</a>
            </li><li class="masthead__menu-item">
              <a href="/publications/" >Publications</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  

  <div class="archive">
    
      <h1 id="page-title" class="page__title">Quick-Start Guide</h1>
    
    <h2 id="input-data">Input Data</h2>

<p>ASTROIDE supports reading ONLY input format csv or compressed csv.</p>

<p>You can download example of astronomical data <a href="https://github.com/MBrahem/ASTROIDE/tree/master/ExampleData">here</a> or all GAIA DR1 <a href="http://cdn.gea.esac.esa.int/Gaia/gdr1/gaia_source/csv/">here</a> and put downloaded files in HDFS.</p>

<p>Example:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd $ASTROIDE_HOME/ExampleData
$ hdfs dfs -mkdir data
$ hdfs dfs -put * data/
</code></pre></div></div>

<p>ASTROIDE allows users to use data whose coordinates are expressed according to the International Celestial Reference System <a href="https://hpiers.obspm.fr/icrs-pc/icrs/icrs.html">ICRS</a>. Other coordinate systems will be supported in future versions.</p>

<h2 id="partitioning">Partitioning</h2>

<p>Partitioning is a fundamental component for parallel data processing. It reduces computer resources when only a sub-part of relevant data are involved in a query, and distributes tasks evenly when the query concerns a large number of partitions. This hence globally improves the query performances.</p>

<p>Partitioning is a mandatory  process for executing astronomical queries efficiently in ASTROIDE.</p>

<p>Using ASTROIDE, partitioning is executed as follows:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ spark-submit --class fr.uvsq.adam.astroide.executor.BuildHealpixPartitioner [ --master &lt;master-url&gt;  ] &lt;astroide.jar&gt; -fs &lt;hdfs&gt; [&lt;schema&gt;] &lt;infile&gt; &lt;separator&gt; &lt;outfile.parquet&gt; &lt;partitionSize&gt; &lt;healpixOrder&gt; &lt;name_coordinates1&gt; &lt;name_coordinates2&gt; &lt;boundariesFile&gt;
</code></pre></div></div>

<p>The above line can be explained as:</p>

<ul>
  <li>
    <p><em>hdfs</em>: hdfs path. For e.g. hdfs://{NameNodeHost}:8020</p>
  </li>
  <li>
    <p><em>schema</em>: text file containing the schema of input file (separator: “,”). If your data already contains the schema, you can skip this option</p>
  </li>
  <li>
    <p><em>infile</em>: path to input file on HDFS where astronomical data are stored</p>
  </li>
  <li>
    <p><em>separator</em>: separator used in the input file (e.g. “,”)</p>
  </li>
  <li>
    <p><em>outfile</em>: path to output parquet file on HDFS where astronomical data will be stored after partitioning</p>
  </li>
  <li>
    <p><em>partitionSize</em>: approximate partition size in MB(recommended 256MB)</p>
  </li>
  <li>
    <p><em>healpixOrder</em>: the value of healpix order to use (recommended value 12)</p>
  </li>
  <li>
    <p><em>name_coordinates1</em>: attribute name of the first spherical coordinates (usually ra)</p>
  </li>
  <li>
    <p><em>name_coordinates2</em>: attribute name of the second spherical coordinates (usually dec)</p>
  </li>
  <li>
    <p><em>boundariesFile</em>: a text file where ASTROIDE will save the metadata (ranges of partitions)
Please precise a path to a local file on your master node.</p>
  </li>
</ul>

<p>Example:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ hdfs dfs -mkdir data
	

$ spark-submit --class fr.uvsq.adam.astroide.executor.BuildHealpixPartitioner  $ASTROIDE_HOME/ProjectJar/astroide.jar -fs hdfs://localhost:8020 data/gaia.csv "," partitioned/gaia.parquet 32 12 ra dec $ASTROIDE_HOME/gaia.txt
</code></pre></div></div>

<p>Or using schema:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ spark-submit --class fr.uvsq.adam.astroide.executor.BuildHealpixPartitioner $ASTROIDE_HOME/ProjectJar/astroide.jar -fs hdfs://localhost:8020  $ASTROIDE_HOME/ExampleData/tycho2Schema.txt data/tycho2.gz "|" partitioned/tycho2.parquet 32 12 ra dec $ASTROIDE_HOME/tycho2.txt
</code></pre></div></div>

<p>ASTROIDE retrieves partition boundaries and stores them as metadata. Note that in our case, all we need to store are the three values (n, l, u) where n is the partition number, l is
the first HEALPix cell of the partition number n and u is the last HEALPix cell of the partition number n. It should also be noted that we store the partitioned files, along with the
metadata, on HDFS and use them for future queries.</p>

<p>Below is an example of small file with 5 partitions:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cat $ASTROIDE_HOME/gaia.txt

[3,268313,340507]
[0,0,86480]
[1,86481,178805]
[2,178807,268308]
</code></pre></div></div>

<p>The partitioned file will be stored as a parquet file that looks like:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ hdfs dfs -ls partitioned/gaia.parquet/

Found 5 items
-rw-r--r--   1 user supergroup          0 2018-06-22 11:32 partitioned/gaia.parquet/_SUCCESS
drwxr-xr-x   - user supergroup          0 2018-06-22 11:32 partitioned/gaia.parquet/nump=0
drwxr-xr-x   - user supergroup          0 2018-06-22 11:32 partitioned/gaia.parquet/nump=1
drwxr-xr-x   - user supergroup          0 2018-06-22 11:32 partitioned/gaia.parquet/nump=2
drwxr-xr-x   - user supergroup          0 2018-06-22 11:32 partitioned/gaia.parquet/nump=3
</code></pre></div></div>

<h2 id="run-astronomical-queries">Run astronomical queries</h2>

<p>AstroSpark focuses on three main basic astronomical queries, these queries require more calculations than ordinary search or join in legacy relational databases:</p>

<ul>
  <li>
    <p>Cone Search is one of the most frequent queries in the astronomical domain. It returns a set of stars whose positions lie within a circular region of the sky.</p>
  </li>
  <li>
    <p>Cross-Matching query aims at identifying and comparing astronomical objects belonging to different observations of the same sky region.</p>
  </li>
  <li>
    <p>kNN query returns the k closest sources from a query point q.</p>
  </li>
</ul>

<p>You can run astronomical queries using object <code class="highlighter-rouge">fr.uvsq.adam.astroide.executor.AstroideQueries</code> which executes ADQL queries using our framework.</p>

<p>Note: Please make sure that your data has been already partitioned to execute astronomcal queries.</p>

<p>After data partitioning, you can start executing astronomical queries using ADQL.</p>

<p>ASTROIDE supports ADQL Standard. It includes three kinds of astronomical operators as follows. All these operators can be directly passed to astroide throught <em>queryFile</em></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ spark-submit --class fr.uvsq.adam.astroide.executor.AstroideQueries [--master &lt;master-url&gt;] &lt;astroide.jar&gt; -fs &lt;hdfs&gt; &lt;file1&gt; &lt;file2&gt; &lt;healpixOrder&gt; &lt;queryFile&gt; &lt;action&gt; [&lt;outfile&gt;]
</code></pre></div></div>

<blockquote>
  <p>For KNN &amp; ConeSearch queries</p>
</blockquote>

<ul>
  <li>
    <p><em>file1</em>: output file created after partitioning (parquet file)</p>
  </li>
  <li>
    <p><em>file2</em>: boundaries file created after partitioning (text file)</p>
  </li>
  <li>
    <p><em>queryFile</em>: ADQL query (text file) see examples below</p>
  </li>
  <li>
    <p><em>action</em>: action that you will execute on query result (show, count, save)</p>
  </li>
  <li>
    <p><em>outfile</em>: output file where result can be saved on HDFS</p>
  </li>
</ul>

<p>If no action is defined, ASTROIDE will show only the execution plan.</p>

<blockquote>
  <p>For CrossMatch queries</p>
</blockquote>

<ul>
  <li>
    <p><em>file1</em>: first dataset (parquet file)</p>
  </li>
  <li>
    <p><em>file2</em>: second dataset (parquet file)</p>
  </li>
  <li>
    <p><em>queryFile</em>: ADQL query (text file) see examples below</p>
  </li>
  <li>
    <p><em>action</em>: action that you will execute on query result (show, count, save)</p>
  </li>
  <li>
    <p><em>outfile</em>: output file where result can be saved on HDFS</p>
  </li>
</ul>

<p>If no action is defined, ASTROIDE will show only the execution plan.</p>

<p>Example:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ spark-submit --class fr.uvsq.adam.astroide.executor.AstroideQueries $ASTROIDE_HOME/ProjectJar/astroide.jar -fs hdfs://localhost:8020 partitioned/gaia.parquet $ASTROIDE_HOME/gaia.txt 12 $ASTROIDE_HOME/ExampleQuery/conesearch.txt show

...
2018-06-22 11:43:59 INFO  DAGScheduler:54 - Job 2 finished: show at AstroideQueries.scala:87, took 0,508019 s
+-------------+------------------+-------------------+
|    source_id|                ra|                dec|
+-------------+------------------+-------------------+
|5050881701504| 44.95293718578692|0.13388443523264248|
|1099511693312|44.966545443077436|0.04631022905873263|
|1614907863552|44.951154531610996|0.10530901086672136|
...
</code></pre></div></div>

<h2 id="queries-examples">Queries Examples</h2>

<p>These are some correct ADQL queries that you can refer to test in ASTROIDE.</p>

<p>You can save only one query in a text file and run your application using <code class="highlighter-rouge">fr.uvsq.adam.astroide.executor.AstroideQueries</code>.</p>

<h3 id="conesearch-queries">ConeSearch Queries</h3>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SELECT * FROM table WHERE 1=CONTAINS(point('icrs',ra,dec),circle('icrs', 44.97845893652677, 0.09258081167082206, 0.05));

SELECT ra,dec,ipix FROM table WHERE 1=CONTAINS(point('icrs',ra,dec),circle('icrs', 44.97845893652677, 0.09258081167082206, 0.05)) ORDER BY ipix;

SELECT source_id,ra FROM table WHERE (1=CONTAINS(point('icrs',ra,dec),circle('icrs', 44.97845893652677, 0.09258081167082206, 0.05)) AND ra &gt; 0);

SELECT ra,dec,ipix FROM (SELECT * FROM table WHERE 1=CONTAINS(point('icrs',ra,dec),circle('icrs', 44.97845893652677, 0.09258081167082206, 0.05))) As t;
</code></pre></div></div>

<h3 id="knn-queries">KNN Queries</h3>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SELECT TOP 10 *, DISTANCE(Point('ICRS', ra, dec), Point('ICRS', 44.97845893652677, 0.09258081167082206)) AS dist FROM table ORDER BY dist;
    
SELECT t.ra, t.dec,t.dist FROM (SELECT TOP 10 *, DISTANCE(Point('ICRS', ra, dec), Point('ICRS', 44.97845893652677, 0.09258081167082206)) AS dist FROM table1 WHERE ra&gt; 0 ORDER BY dist) AS t;
</code></pre></div></div>

<h3 id="crossmatching-queries">CrossMatching Queries</h3>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SELECT * FROM table JOIN table2 ON 1=CONTAINS(point('icrs',table.ra,table.dec),circle('icrs',table2.ra,table2.dec,0.01));

SELECT * FROM table JOIN table2 ON 1=CONTAINS(point('icrs',table.ra,table.dec),circle('icrs',table2.ra,table2.dec,0.01)) WHERE table.ra&gt;0 ORDER BY table.ra;

SELECT * FROM (SELECT table.source_id, table.ipix, table2.ipix FROM table JOIN table2 ON 1=CONTAINS(point('icrs',table.ra,table.dec),circle('icrs',table2.ra,table2.dec,0.01))) AS t;
</code></pre></div></div>

<p>Please consider that ASTROIDE translates these three types of queries into internal representation. ASTROIDE does not translate all features of ADQL language. 
For example, the second KNN query is translated into an equivalent query as follows:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Translated Query ==
SELECT t.ra , t.dec , t.dist
FROM (SELECT * , SphericalDistance(ra, dec, 44.97845893652677, 0.09258081167082206) AS dist
FROM table1
WHERE ra &gt; 0
ORDER BY dist ASC
Limit 10) AS t
</code></pre></div></div>

<p>ASTROIDE injects some optimizations rules into the Spark optimizer. 
For such query, the objective is to avoid reading unnecessary data, and to load only required partitions
using <code class="highlighter-rouge">PartitionFilters: [isnotnull(nump#58), (nump#58 = 0)]</code></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>== Physical Plan ==
TakeOrderedAndProject(limit=10, orderBy=[dist#120 ASC NULLS FIRST], output=[ra#4,dec#6,dist#120])
+- *Project [ra#4, dec#6, if ((isnull(cast(ra#4 as double)) || isnull(cast(dec#6 as double)))) null else UDF:SphericalDistance(cast(ra#4 as double), cast(dec#6 as double), 44.97845893652677, 0.09258081167082206) AS dist#120]
    +- *Filter (isnotnull(ra#4) &amp;&amp; (cast(ra#4 as int) &gt; 0))
        +- *FileScan parquet [ra#4,dec#6,nump#58] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://UbuntuMaster:9000/bucketby/gaiatest.parquet], PartitionCount: 1, PartitionFilters: [isnotnull(nump#58), (nump#58 = 0)], PushedFilters: [IsNotNull(ra)], ReadSchema: struct&lt;ra:string,dec:string&gt;
</code></pre></div></div>

<h2 id="dataframe-api">Dataframe API</h2>

<p>A second option for executing astronomical queries is to use the Spark DataFrame API using Scala.</p>

<p>If you need to test other queries using the DataFrame interface, you can refer to other classes in package <code class="highlighter-rouge">fr.uvsq.adam.astroide.executor</code> called <code class="highlighter-rouge">RunCrossMatch</code> <code class="highlighter-rouge">RunConeSearch</code> <code class="highlighter-rouge">RunKNN</code></p>

<h3 id="cross-matching">Cross-matching</h3>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-submit --class fr.uvsq.adam.astroide.executor.RunCrossMatch &lt;application-jar&gt; &lt;file1&gt; &lt;file2&gt; &lt;radius&gt; &lt;healpixOrder&gt;
</code></pre></div></div>

<p>Cross matching imports this package</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import fr.uvsq.adam.astroide.queries.optimized.CrossMatch._
</code></pre></div></div>

<p>Given a dataFrame representing the first dataset, this class execute a crossmatch using a precised radius by doing the following:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val output = df1.ExecuteXMatch(session, df2, radius)
</code></pre></div></div>

<p>This produces a new dataframe called output which is the result of crossmatching two input dataframes.</p>



<ul class="taxonomy__index">
  
  
</ul>




  </div>
</div>
    </div>

    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2018 Mariem Brahem. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.5.0/js/all.js" integrity="sha384-GqVMZRt5Gn7tB9D9q7ONtcp4gtHIUEW/yG7h98J7IpE3kpi+srfFyyB/04OV6pG0" crossorigin="anonymous"></script>








  </body>
</html>
